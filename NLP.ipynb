{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/elainny/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import all packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Word cloud plots for Names\n",
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "# LDA & LSI packages\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from gensim import models, corpora\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import similarities\n",
    "# Split dataset package\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Random forest packages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidfV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report as report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "#Evaluation on best model\n",
    "from sklearn.metrics import precision_recall_fscore_support as f_score\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "\n",
    "df = pd.read_csv('Data/cleaned-data.csv')\n",
    "train = pd.read_csv('Data/cleaned-train.csv')\n",
    "test = pd.read_csv('Data/cleaned-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fill out all NaN values under Description column with 'For Adoption'\n",
    "\n",
    "train['Descrption'] = train['Description'].fillna('For Adoption', inplace = True)\n",
    "#train_null = np.array(train[train['Description'].isnull() == True].index)\n",
    "#train = train.drop(train_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word cloud: cat name\n",
    "plt.figure(figsize=(20, 8))\n",
    "bg_pic = imread('dog-paw.png')\n",
    "image_colors = ImageColorGenerator(bg_pic)\n",
    "\n",
    "\n",
    "cat_name = ' '.join(df.loc[df['Type'] == 'Cat', 'Name'].fillna('').values)\n",
    "wc_cat = WordCloud(mask=bg_pic,background_color='white',scale=20,max_words=300).generate(cat_name)\n",
    "\n",
    "plt.imshow(wc_cat.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('cat.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# wordÂ cloud: dog name\n",
    "plt.figure(figsize=(20, 8))\n",
    "dog_name = ' '.join(df.loc[df['Type'] == 'Dog', 'Name'].fillna('').values)\n",
    "wc_dog = WordCloud(mask=bg_pic,background_color='white',scale=20,max_words=300).generate(dog_name)\n",
    "plt.imshow(wc_dog.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('dog.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & LSI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_data by selecting Description columns in train data\n",
    "train_data = train['Description'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords, lemmatizer, and data cleaning process\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# Lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# Stemming\n",
    "stemming = nltk.PorterStemmer()\n",
    "\n",
    "\n",
    "def cleandata(review) :\n",
    "    clean_des = re.sub('[^a-zA-Z]', ' ', str(review)) # Remove punctuation/words not starting with alphabet\n",
    "    clean_des = clean_des.lower() # make words lower cases\n",
    "    words = word_tokenize(clean_des) # tokenize\n",
    "    words = [w for w in words if not w in stop_words] # stop words removal\n",
    "    words = [stemming.stem(word) for word in words] # Stemming\n",
    "    words = [wordnet_lemmatizer.lemmatize(w) for w in words] #Lemmatize words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of topics\n",
    "t = 10\n",
    "\n",
    "cleaned = []\n",
    "for description in train_data:\n",
    "    cleaned.append(cleandata(description))\n",
    "# Create a Dictionary associate word to id\n",
    "D = corpora.Dictionary(cleaned)\n",
    "\n",
    "# Transform texts to numeric\n",
    "corpra = [D.doc2bow(i) for i in cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model\n",
    "lda = models.LdaModel(corpus=corpra, num_topics=t, id2word=D)\n",
    "\n",
    "print('LDA model')\n",
    "for index in range(0,t):\n",
    "    # top 9 topics\n",
    "    print(\"Topic Number %s:\" % str(index+1), lda.print_topic(index, 9))\n",
    "print(\"-\" * 117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSI model\n",
    "lsi = models.LsiModel(corpus=corpra, num_topics=t, id2word=D)\n",
    "\n",
    "print('LSI model')\n",
    "for index in range(0,t):\n",
    "    # top 9 topics\n",
    "    print(\"Topic Number %s:\" % str(index+1), lsi.print_topic(index, 9))\n",
    "print(\"-\" * 117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick one description from test to predict similarity.\n",
    "import random\n",
    "i = random.randint(1,3948) # since my test dataset has 3498 values \n",
    "print(i)\n",
    "test_data = test.loc[i,'Description']\n",
    "print('-----This is the description from test that I am going to predict:-----')\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LDA model and LSI model to predict similarity.\n",
    "lda_i = similarities.MatrixSimilarity(lda[corpra])\n",
    "m = D.doc2bow(cleandata(test_data))\n",
    "# Perform some queries\n",
    "similar_lda = lda_i[lda[m]]\n",
    "# Sort the similarities\n",
    "LDA = sorted(enumerate(similar_lda), key=lambda item: -item[1])\n",
    "# Top 10 most similar documents:\n",
    "print(LDA[:10])\n",
    "# The most similar document\n",
    "doc_id, similarity = LDA[1]\n",
    "print(train_data[doc_id][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same similarity queries by using LSI model\n",
    "lsi_i = similarities.MatrixSimilarity(lsi[corpra])\n",
    "similar_lsi = lsi_i[lsi[m]]\n",
    "LSI = sorted(enumerate(similar_lsi), key=lambda item:-item[1])\n",
    "print(LSI[:10])\n",
    "doc_id_lsi, similarity_lsi = LSI[1]\n",
    "print(train_data[doc_id][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 2)\n"
     ]
    }
   ],
   "source": [
    "# Choose the correct columns\n",
    "train = train[['Description','AdoptionSpeed']]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Descrtion based on AdoptionSpeed, so need to seperate train into 5 groups\n",
    "train0 = np.array(train[train['AdoptionSpeed'] == 0].index)\n",
    "train1 = np.array(train[train['AdoptionSpeed'] == 1].index)\n",
    "train2 = np.array(train[train['AdoptionSpeed'] == 2].index)\n",
    "train3 = np.array(train[train['AdoptionSpeed'] == 3].index)\n",
    "train4 = np.array(train[train['AdoptionSpeed'] == 4].index)\n",
    "\n",
    "adoption1 = []\n",
    "adoption2 = []\n",
    "adoption3 = []\n",
    "adoption4 = []\n",
    "\n",
    "for index in range(len(train0)):\n",
    "    adoption1.append(train1[index])\n",
    "    adoption2.append(train2[index])\n",
    "    adoption3.append(train3[index])\n",
    "    adoption4.append(train4[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the X and Y dataset according to different AdoptionSpeeds\n",
    "\n",
    "X = pd.concat([train['Description'].reindex(train0), \n",
    "               train['Description'].reindex(adoption1),\n",
    "               train['Description'].reindex(adoption2), \n",
    "               train['Description'].reindex(adoption3),\n",
    "               train['Description'].reindex(adoption4)])\n",
    "\n",
    "Y = pd.concat([train['AdoptionSpeed'].reindex(train0), \n",
    "               train['AdoptionSpeed'].reindex(adoption1),\n",
    "               train['AdoptionSpeed'].reindex(adoption2), \n",
    "               train['AdoptionSpeed'].reindex(adoption3),\n",
    "               train['AdoptionSpeed'].reindex(adoption4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1537,), (513,), (1537,), (513,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the X and Y data into train and valid:\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=.25, random_state=42)\n",
    "X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data cleaning process(tokenize, lower cases, lemmatizer) for random forest\n",
    "# and apply data cleaning on X_train and X_valid\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer() # same as LDA and LSI but do not remove stop words\n",
    "\n",
    "def nlp_rf(reviews):\n",
    "    token = [word_tokenize(i) for i in reviews]\n",
    "    token1 = [[d.lower() for d in words if d.isalpha() == True] for words in token]\n",
    "    lemma = [[wordnet_lemmatizer.lemmatize(word) for word in doc] for doc in token1]\n",
    "    review = [\" \".join(i) for i in lemma]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data cleaning on X_train and X_valid\n",
    "\n",
    "X_train_clean = nlp_rf(X_train)\n",
    "X_valid_clean = nlp_rf(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning models on Description\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "tfvec = tfidfV(stop_words='english', ngram_range=(1, 1), lowercase=False)\n",
    "mode = Pipeline([('vectorizer', tfvec),('rf', MultinomialNB(alpha=0.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.36      0.26      0.30       107\n",
      "          1       0.29      0.28      0.28       108\n",
      "          2       0.17      0.21      0.19        90\n",
      "          3       0.24      0.28      0.26       110\n",
      "          4       0.26      0.24      0.25        98\n",
      "\n",
      "avg / total       0.27      0.26      0.26       513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elainny/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/Users/elainny/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "# Y_pred and report\n",
    "model.fit(X_train_clean, Y_train)\n",
    "Y_prediction = model.predict(X_valid_clean)\n",
    "print(report(Y_valid, Y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import package: string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Cocoa is a quite, calm kitten, loves to be clo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>they r ol so cute :) it juz a matter me dun hv...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Kittens up for adoption. Age 2 months old. Pot...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>One of 2 remaining stray puppies awaiting adop...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The little has a straight up ears and its voic...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  AdoptionSpeed\n",
       "995  Cocoa is a quite, calm kitten, loves to be clo...              2\n",
       "996  they r ol so cute :) it juz a matter me dun hv...              4\n",
       "997  Kittens up for adoption. Age 2 months old. Pot...              2\n",
       "998  One of 2 remaining stray puppies awaiting adop...              2\n",
       "999  The little has a straight up ears and its voic...              4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first 1000 rows to do this, since there are 14993 rows, which needs plenty of time to run\n",
    "train1000 = train[:1000]\n",
    "train1000.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply puctuation removal, tokenize, stopwords removal, stemming and lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use the same cleandata function as LDA/LSI model\n",
    "# define stopwords, lemmatizer, and data cleaning process\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# Lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# Stemming\n",
    "stemming = nltk.PorterStemmer()\n",
    "\n",
    "\n",
    "def cleandata(review) :\n",
    "    clean_des = re.sub('[^a-zA-Z]', ' ', str(review)) # Remove punctuation/words not starting with alphabet\n",
    "    clean_des = clean_des.lower() # make words lower cases\n",
    "    words = word_tokenize(clean_des) # tokenize\n",
    "    words = [w for w in words if not w in stop_words] # stop words removal\n",
    "    words = [stemming.stem(word) for word in words] # Stemming\n",
    "    words = [wordnet_lemmatizer.lemmatize(w) for w in words] #Lemmatize words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4269)\n"
     ]
    }
   ],
   "source": [
    "# Apply CountVectorizer: N-Grams\n",
    "# Do the 2-gram\n",
    "cv_vectorizer = CountVectorizer(ngram_range=(2,2),analyzer=cleandata)\n",
    "X_cv = cv_vectorizer.fit_transform(train1000['Description'])\n",
    "print(X_cv.shape)\n",
    "#print(cv_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abam</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abang</th>\n",
       "      <th>abit</th>\n",
       "      <th>abl</th>\n",
       "      <th>abod</th>\n",
       "      <th>abott</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absolut</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yr</th>\n",
       "      <th>yucca</th>\n",
       "      <th>yuen</th>\n",
       "      <th>yusuf</th>\n",
       "      <th>yy</th>\n",
       "      <th>zen</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zoey</th>\n",
       "      <th>zorro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 4269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abam  abandon  abang  abit  abl  abod  abott  abroad  abscess  absolut  \\\n",
       "0     0        0      0     0    0     0      0       0        0        0   \n",
       "1     0        0      0     0    0     0      0       0        0        0   \n",
       "2     0        0      0     0    0     0      0       0        0        0   \n",
       "3     0        0      0     0    0     0      0       0        0        0   \n",
       "4     0        0      0     0    0     0      0       0        0        0   \n",
       "5     0        0      0     0    0     0      0       0        0        0   \n",
       "6     0        0      0     0    0     0      0       0        0        0   \n",
       "7     0        0      0     0    0     0      0       0        0        0   \n",
       "8     0        0      0     0    0     0      0       0        0        0   \n",
       "9     0        0      0     0    0     0      0       0        0        0   \n",
       "\n",
       "   ...    your  yr  yucca  yuen  yusuf  yy  zen  zenith  zoey  zorro  \n",
       "0  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "1  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "2  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "3  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "4  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "5  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "6  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "7  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "8  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "9  ...       0   0      0     0      0   0    0       0     0      0  \n",
       "\n",
       "[10 rows x 4269 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdf_cv = pd.DataFrame(X_cv.toarray(), columns=cv_vectorizer.get_feature_names())\n",
    "Xdf_cv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4269)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elainny/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = tfidfV(analyzer=cleandata)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(train1000['Description'])\n",
    "print(X_tfidf.shape)\n",
    "#print(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abam</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abang</th>\n",
       "      <th>abit</th>\n",
       "      <th>abl</th>\n",
       "      <th>abod</th>\n",
       "      <th>abott</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absolut</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yr</th>\n",
       "      <th>yucca</th>\n",
       "      <th>yuen</th>\n",
       "      <th>yusuf</th>\n",
       "      <th>yy</th>\n",
       "      <th>zen</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zoey</th>\n",
       "      <th>zorro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 4269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abam  abandon  abang  abit  abl  abod  abott  abroad  abscess  absolut  \\\n",
       "0   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "1   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "2   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "3   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "4   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "5   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "6   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "7   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "8   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "9   0.0      0.0    0.0   0.0  0.0   0.0    0.0     0.0      0.0      0.0   \n",
       "\n",
       "   ...    your   yr  yucca  yuen  yusuf   yy  zen  zenith  zoey  zorro  \n",
       "0  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "1  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "2  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "3  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "4  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "5  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "6  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "7  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "8  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "9  ...     0.0  0.0    0.0   0.0    0.0  0.0  0.0     0.0   0.0    0.0  \n",
       "\n",
       "[10 rows x 4269 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdf_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "Xdf_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elainny/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/elainny/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>length</th>\n",
       "      <th>punctuation-percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3</td>\n",
       "      <td>325</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  AdoptionSpeed  length  \\\n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...              2     291   \n",
       "1  I just found it alone yesterday near my apartm...              0      96   \n",
       "2  Their pregnant mother was dumped by her irresp...              3     325   \n",
       "3  Good guard dog, very alert, active, obedience ...              2     122   \n",
       "4  This handsome yet cute boy is up for adoption....              2     310   \n",
       "\n",
       "   punctuation-percentage  \n",
       "0                     2.7  \n",
       "1                     2.1  \n",
       "2                     2.8  \n",
       "3                     5.7  \n",
       "4                     2.9  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Machine Learning Classifiers with Random Forest model and GridSearchCV\n",
    "# Need to calculate the length and punctuation percentage of each description\n",
    "# 1st: calculate length of message without counting space in\n",
    "train1000['length'] = train1000['Description'].apply(lambda length: len(length) - length.count(\" \"))\n",
    "\n",
    "#2nd: function of puncutuation number to apply on every description\n",
    "def punct_percentage(description):\n",
    "    count = sum([1 for symbol in description if symbol in string.punctuation]) # string.punctuation defined above\n",
    "    return 100 * round(count/(len(description) - description.count(\" \")), 3)\n",
    "\n",
    "train1000['punctuation-percentage'] = train1000['Description'].apply(lambda des: punct_percentage(des))\n",
    "\n",
    "train1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring parameters using GridSearchCV\n",
    "# TF-IDF\n",
    "X_tfidf_clf = pd.concat([train1000['length'], train1000['punctuation-percentage'], \n",
    "                         pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "# CountVectorizer\n",
    "X_cv_clf = pd.concat([train1000['length'], train1000['punctuation-percentage'], \n",
    "                                   pd.DataFrame(X_cv.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.016172</td>\n",
       "      <td>0.028979</td>\n",
       "      <td>0.040988</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.353234</td>\n",
       "      <td>0.290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.038602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.728223</td>\n",
       "      <td>0.180652</td>\n",
       "      <td>0.058611</td>\n",
       "      <td>0.010873</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>2</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.614037</td>\n",
       "      <td>0.428615</td>\n",
       "      <td>0.038705</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.381188</td>\n",
       "      <td>0.323383</td>\n",
       "      <td>0.295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.039952</td>\n",
       "      <td>2</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.122860</td>\n",
       "      <td>0.034588</td>\n",
       "      <td>0.063717</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.351485</td>\n",
       "      <td>0.323383</td>\n",
       "      <td>0.305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>4</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.98375</td>\n",
       "      <td>0.98625</td>\n",
       "      <td>0.983811</td>\n",
       "      <td>0.985502</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.127324</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.038569</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.311881</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.035598</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7        3.016172      0.028979         0.040988        0.002621   \n",
       "8        5.728223      0.180652         0.058611        0.010873   \n",
       "11       4.614037      0.428615         0.038705        0.002646   \n",
       "5        5.122860      0.034588         0.063717        0.003411   \n",
       "10       3.127324      0.049799         0.038569        0.001361   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "8               90                300   \n",
       "11            None                300   \n",
       "5               60                300   \n",
       "10            None                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.356436   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.326733   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.381188   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.351485   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.311881   \n",
       "\n",
       "    split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "7            0.353234              0.290       ...                   0.337   \n",
       "8            0.373134              0.285       ...                   0.332   \n",
       "11           0.323383              0.295       ...                   0.332   \n",
       "5            0.323383              0.305       ...                   0.326   \n",
       "10           0.328358              0.325       ...                   0.325   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "7         0.038602                1            0.986216            0.988736   \n",
       "8         0.048708                2            0.986216            0.988736   \n",
       "11        0.039952                2            0.986216            0.988736   \n",
       "5         0.029464                4            0.984962            0.988736   \n",
       "10        0.035598                5            0.986216            0.988736   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "7              0.99000             0.98875            0.986301   \n",
       "8              0.99000             0.98875            0.986301   \n",
       "11             0.99000             0.98875            0.986301   \n",
       "5              0.98375             0.98625            0.983811   \n",
       "10             0.99000             0.98875            0.986301   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "7           0.988001         0.001495  \n",
       "8           0.988001         0.001495  \n",
       "11          0.988001         0.001495  \n",
       "5           0.985502         0.001857  \n",
       "10          0.988001         0.001495  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For CountVectorizer\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs_cv = GridSearchCV(rf, param, cv=5, n_jobs=-1)# n_jobs=-1 for parallelizing search\n",
    "gs_cv_fit = gs_cv.fit(X_cv_clf, train1000['AdoptionSpeed'])\n",
    "pd.DataFrame(gs_cv_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean_test_score for n_estimators =150 and max_depth = 90 gives the best result. Where n_estimators is the number of trees in the forest.(group of decision trees) and max_depth is the max number of levels in each decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.601240</td>\n",
       "      <td>0.363767</td>\n",
       "      <td>0.038085</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.381188</td>\n",
       "      <td>0.353234</td>\n",
       "      <td>0.315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.262356</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979950</td>\n",
       "      <td>0.987484</td>\n",
       "      <td>0.97875</td>\n",
       "      <td>0.98625</td>\n",
       "      <td>0.982565</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>0.003413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.735688</td>\n",
       "      <td>0.054469</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 150}</td>\n",
       "      <td>0.351485</td>\n",
       "      <td>0.363184</td>\n",
       "      <td>0.295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.033227</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.954944</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.94375</td>\n",
       "      <td>0.947696</td>\n",
       "      <td>0.941740</td>\n",
       "      <td>0.010182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.537186</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>0.052905</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 300}</td>\n",
       "      <td>0.351485</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.033747</td>\n",
       "      <td>3</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.956195</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>0.947696</td>\n",
       "      <td>0.943493</td>\n",
       "      <td>0.009048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.135664</td>\n",
       "      <td>0.057850</td>\n",
       "      <td>0.035122</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.361386</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.034697</td>\n",
       "      <td>3</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11       4.601240      0.363767         0.038085        0.001962   \n",
       "5        5.262356      0.056106         0.061023        0.002477   \n",
       "1        1.735688      0.054469         0.035533        0.002022   \n",
       "2        3.537186      0.038153         0.052905        0.005119   \n",
       "10       3.135664      0.057850         0.035122        0.002196   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "11            None                300   \n",
       "5               60                300   \n",
       "1               30                150   \n",
       "2               30                300   \n",
       "10            None                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.381188   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.336634   \n",
       "1     {'max_depth': 30, 'n_estimators': 150}           0.351485   \n",
       "2     {'max_depth': 30, 'n_estimators': 300}           0.351485   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.361386   \n",
       "\n",
       "    split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "11           0.353234              0.315       ...                   0.350   \n",
       "5            0.373134              0.310       ...                   0.343   \n",
       "1            0.363184              0.295       ...                   0.335   \n",
       "2            0.358209              0.300       ...                   0.335   \n",
       "10           0.343284              0.295       ...                   0.335   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "11        0.038028                1            0.986216            0.988736   \n",
       "5         0.033783                2            0.979950            0.987484   \n",
       "1         0.033227                3            0.924812            0.954944   \n",
       "2         0.033747                3            0.929825            0.956195   \n",
       "10        0.034697                3            0.986216            0.988736   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "11             0.99000             0.98875            0.986301   \n",
       "5              0.97875             0.98625            0.982565   \n",
       "1              0.93750             0.94375            0.947696   \n",
       "2              0.93750             0.94625            0.947696   \n",
       "10             0.99000             0.98875            0.986301   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "11          0.988001         0.001495  \n",
       "5           0.983000         0.003413  \n",
       "1           0.941740         0.010182  \n",
       "2           0.943493         0.009048  \n",
       "10          0.988001         0.001495  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For TF-IDF\n",
    "gs_tfidf = GridSearchCV(rf, param, cv=5, n_jobs=-1)# n_jobs=-1 for parallelizing search\n",
    "gs_tfidf_fit = gs_tfidf.fit(X_tfidf_clf, train1000['AdoptionSpeed'])\n",
    "pd.DataFrame(gs_tfidf_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean_test_score for n_estimators =300  and max_depth = 0 gives the best result. Where n_estimators is the number of trees in the forest.(group of decision trees) and max_depth is the max number of levels in each decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 3), (200, 3), (800,), (200,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset\n",
    "X=train1000[['Description', 'length', 'punctuation-percentage']]\n",
    "y=train1000['AdoptionSpeed']\n",
    "\n",
    "X_train1000, X_test1000, y_train1000, y_test1000 = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "X_train1000.shape, X_test1000.shape, y_train1000.shape, y_test1000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elainny/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.285 --- Recall: 0.285 --- F1-Score: 0.285 --- Accuracy: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elainny/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1045: UserWarning: Note that pos_label (set to 'spam') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of model: on tfidf\n",
    "# Variables define\n",
    "tfidf_vectorizer1000 = tfidfV(analyzer=cleandata) # defined before\n",
    "tfidf_fit1000 = tfidf_vectorizer1000.fit(X_train1000['Description'])\n",
    "\n",
    "tfidf_train1000 = tfidf_fit1000.transform(X_train1000['Description'])\n",
    "tfidf_test1000 = tfidf_fit1000.transform(X_test1000['Description'])\n",
    "\n",
    "X_vectorizer_train1000 = pd.concat([X_train1000[['length', 'punctuation-percentage']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train1000.toarray())], axis=1)\n",
    "X_vectorizer_test1000 = pd.concat([X_test1000[['length', 'punctuation-percentage']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test1000.toarray())], axis=1)\n",
    "\n",
    "# Build model\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=None, n_jobs=-1)\n",
    "rf_model = rf.fit(X_vectorizer_train1000, y_train1000)\n",
    "y_prediction1 = rf_model.predict(X_vectorizer_test1000)\n",
    "\n",
    "precision, recall, fscore, train_support = f_score(y_test1000, y_prediction1, pos_label='spam', average='micro')\n",
    "print('Precision: {} --- Recall: {} --- F1-Score: {} --- Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round(fscore,3), round(accuracy(y_test1000,y_prediction1), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elainny/anaconda/lib/python3.6/site-packages/matplotlib/font_manager.py:1238: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEaCAYAAADXOHYcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix: tfidf\n",
    "matrix = confusion_matrix(y_test1000, y_prediction1)\n",
    "class_label = ['0','1','2','3','4']\n",
    "matrix_df = pd.DataFrame(matrix, index=class_label,columns=class_label)\n",
    "sns.heatmap(matrix_df, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.325 --- Recall: 0.325 --- F1-Score: 0.325 --- Accuracy: 0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elainny/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1045: UserWarning: Note that pos_label (set to 'spam') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of model: on CountVectorizer\n",
    "# Variables define\n",
    "cv1000 = CountVectorizer(ngram_range=(2,2),analyzer=cleandata) # defined before\n",
    "cv_fit1000 = cv1000.fit(X_train1000['Description'])\n",
    "\n",
    "cv_train1000 = cv_fit1000.transform(X_train1000['Description'])\n",
    "cv_test1000 = cv_fit1000.transform(X_test1000['Description'])\n",
    "\n",
    "X_cv_train1000 = pd.concat([X_train1000[['length', 'punctuation-percentage']].reset_index(drop=True), \n",
    "           pd.DataFrame(cv_train1000.toarray())], axis=1)\n",
    "X_cv_test1000 = pd.concat([X_test1000[['length', 'punctuation-percentage']].reset_index(drop=True), \n",
    "           pd.DataFrame(cv_test1000.toarray())], axis=1)\n",
    "\n",
    "# Build model\n",
    "rf_cv = RandomForestClassifier(n_estimators=150, max_depth=90, n_jobs=-1)\n",
    "rf_model_cv = rf_cv.fit(X_cv_train1000, y_train1000)\n",
    "y_prediction_cv = rf_model_cv.predict(X_cv_test1000)\n",
    "\n",
    "precision, recall, fscore, train_support = f_score(y_test1000, y_prediction_cv, pos_label='spam', average='micro')\n",
    "print('Precision: {} --- Recall: {} --- F1-Score: {} --- Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round(fscore,3), round(accuracy(y_test1000,y_prediction_cv), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEaCAYAAAAIdgwDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix: CountVectorizer\n",
    "matrixcv = confusion_matrix(y_test1000, y_prediction_cv)\n",
    "class_label = ['0','1','2','3','4']\n",
    "matrixcv_df = pd.DataFrame(matrixcv, index=class_label,columns=class_label)\n",
    "sns.heatmap(matrixcv_df, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix of best CountVectorizer model\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
